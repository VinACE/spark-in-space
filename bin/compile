#!/usr/bin/env bash
# bin/compile <build-dir> <cache-dir> <env-dir>
# heroku inline buildpack

set -e

build_dir=$1
cache_dir=$2
env_dir=$3
bp_dir=$(dirname $(dirname $0))

cd $build_dir

fetch_spark_tarball() {
    local version="1.6.1"
    local hadoop="2.6"
    local tarball_file="spark-$version-bin-hadoop$hadoop.tgz"
    local stack="cedar-14"
    local spark_tarball_url="https://s3-external-1.amazonaws.com/heroku-spark/spark-$version-bin-hadoop$hadoop.tgz"
    local dest_path="$cache_dir/$stack/$tarball_file"

    if [ -f "$dest_path" ]; then
        echo -n "cat $dest_path"
    else
        echo -n "curl -s -L $spark_tarball_url"
    fi
}

start() {
  echo -n "-----> $@..."
}

finish() {
  echo " Done."
}


start Installing Spark
$(fetch_spark_tarball) | tar xzC $build_dir
mv $build_dir/spark-1.6.1-bin-hadoop2.6 $build_dir/spark-home
finish Installing Spark


start Configuring Spark
rm -rf $build_dir/spark-home/lib/spark-examples-1.6.1-hadoop2.6.0.jar
mv $bp_dir/conf/spark-env.sh $build_dir/spark-home/conf
finish Configuring Spark

start Installing s3a:// HDFS Support
curl -s -O https://s3.amazonaws.com/heroku-spark/libhadoop.so.1.0.0
curl -s -O https://s3.amazonaws.com/heroku-spark/libhdfs.so.0.0.0
curl -s -O https://s3.amazonaws.com/heroku-spark/hadoop-aws-shaded-no-jackson-0.1-SNAPSHOT-shaded.jar
mv libhadoop.so.1.0.0 spark-home/lib/libhadoop.so
mv libhdfs.so.0.0.0 spark-home/lib/libhdfs.so
mv hadoop-aws-shaded-no-jackson-0.1-SNAPSHOT-shaded.jar spark-home/lib
finish Installing s3a:// HDFS Support



